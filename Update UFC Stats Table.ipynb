{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ae3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note: run this script when you already have the \"Complete Stats.csv\" dataframe saved. \n",
    "This script finds the latest fights by referencing that table and updates both the \"Complete Stats.csv\" and \n",
    "the \"Normalized Stats Table.csv\" \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fbb303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Getting latest date from our current dataset\n",
    "current_df = pd.read_csv(\"Complete Stats.csv\")\n",
    "current_df[\"dates\"] = pd.to_datetime(current_df[\"dates\"])\n",
    "\n",
    "latest_date = current_df[\"dates\"].max()\n",
    "print(latest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4843cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://www.ufcstats.com/statistics/events/completed?page=all\")\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "s = soup.find('section', class_ = 'b-statistics__section' )\n",
    "pages = s.find_all('a', class_ = 'b-link b-link_style_black')\n",
    "hrefs_start = [a['href'] for a in pages]\n",
    "# Pulling in the 500 latest events.\n",
    "hrefs_start = hrefs_start[0:499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d51c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing variables\n",
    "stats_url = []\n",
    "fighter1=[]\n",
    "fighter2=[]\n",
    "weight = []\n",
    "method =[]\n",
    "rounds =[]\n",
    "times = []\n",
    "dates = []\n",
    "locations = []\n",
    "event = []\n",
    "index_value = 0\n",
    "\n",
    "# Getting first date to start the loop\n",
    "url = hrefs_start[index_value]\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "table = soup.find('table')\n",
    "rows = table.find_all('tr')\n",
    "rows = rows[1:]\n",
    "for row in rows:\n",
    "    date = soup.find('li', class_ = 'b-list__box-list-item')\n",
    "    date = date.get_text(strip=True)[5:]\n",
    "    date = pd.to_datetime(date)\n",
    "\n",
    "# Running while loop to find URLS before our latest date to avoid reading in unneccessary data\n",
    "while date > latest_date:\n",
    "    time.sleep(1)\n",
    "    url = hrefs_start[index_value]\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "    rows = rows[1:]\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        data = [col.get_text(strip=True) for col in cols][6:]\n",
    "        weight.append(data[0])\n",
    "        method.append(data[1])\n",
    "        rounds.append(data[2])\n",
    "        times.append(data[3])\n",
    "        fighters = row.find_all('a', class_ =\"b-link b-link_style_black\")\n",
    "        names = [a.get_text(strip = True) for a in fighters]\n",
    "        fighter1.append(names[0])\n",
    "        fighter2.append(names[1])\n",
    "        stat_link = row.get('data-link')\n",
    "        \n",
    "        if stat_link != '' or stat_link is not None:\n",
    "            stats_url.append(row.get('data-link'))\n",
    "        else: stats_url.append(\"No Link\")\n",
    "\n",
    "        location = soup.find_all('li', class_ = 'b-list__box-list-item')\n",
    "        locations.append(location[1].get_text(strip=True)[9:])\n",
    "        date = soup.find('li', class_ = 'b-list__box-list-item')\n",
    "        date = date.get_text(strip=True)[5:]\n",
    "        date = pd.to_datetime(date)\n",
    "        dates.append(date)\n",
    "        event.append(soup.find('h2').get_text(strip=True))\n",
    "    index_value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f40aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({\n",
    "\"stats_url\" : stats_url,\n",
    "\"fighter1\" : fighter1,\n",
    "\"fighter2\" : fighter2,\n",
    "\"weight\" : weight,\n",
    "\"method\" : method,\n",
    "\"rounds\" : rounds,\n",
    "\"times\" : times,\n",
    "\"dates\" : dates,\n",
    "\"locations\" : locations,\n",
    "\"event\" : event\n",
    "})\n",
    "\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c7516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succcess count: 1\n",
      "Succcess count: 2\n",
      "Succcess count: 3\n",
      "Succcess count: 4\n",
      "Succcess count: 5\n",
      "Succcess count: 6\n",
      "Succcess count: 7\n",
      "Succcess count: 8\n",
      "Succcess count: 9\n",
      "Succcess count: 10\n",
      "Succcess count: 11\n",
      "Succcess count: 12\n",
      "Succcess count: 13\n",
      "Succcess count: 14\n",
      "Succcess count: 15\n",
      "Succcess count: 16\n",
      "Succcess count: 17\n",
      "Succcess count: 18\n",
      "Succcess count: 19\n",
      "Succcess count: 20\n",
      "Succcess count: 21\n",
      "Succcess count: 22\n",
      "Succcess count: 23\n",
      "Succcess count: 24\n",
      "Succcess count: 25\n",
      "Succcess count: 26\n",
      "Succcess count: 27\n",
      "Succcess count: 28\n",
      "Succcess count: 29\n",
      "Succcess count: 30\n",
      "Succcess count: 31\n",
      "Succcess count: 32\n",
      "Succcess count: 33\n",
      "Succcess count: 34\n",
      "Succcess count: 35\n",
      "Succcess count: 36\n",
      "Succcess count: 37\n",
      "Succcess count: 38\n",
      "Succcess count: 39\n",
      "Succcess count: 40\n",
      "Succcess count: 41\n",
      "Succcess count: 42\n",
      "Succcess count: 43\n",
      "Succcess count: 44\n",
      "Succcess count: 45\n",
      "Succcess count: 46\n",
      "Succcess count: 47\n",
      "Succcess count: 48\n",
      "Succcess count: 49\n",
      "Succcess count: 50\n",
      "Succcess count: 51\n",
      "Succcess count: 52\n",
      "Succcess count: 53\n",
      "Succcess count: 54\n",
      "Succcess count: 55\n",
      "Succcess count: 56\n",
      "Succcess count: 57\n",
      "Succcess count: 58\n",
      "Succcess count: 59\n",
      "Succcess count: 60\n",
      "Succcess count: 61\n",
      "Succcess count: 62\n",
      "Succcess count: 63\n"
     ]
    }
   ],
   "source": [
    "# Using URL's from new_df to scrape the rest of the data\n",
    "fight_details_links = new_df['stats_url']\n",
    "\n",
    "all_data = []\n",
    "\n",
    "failed_requests = []\n",
    "\n",
    "connect_timeout = 6\n",
    "read_timeout = 60\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "\n",
    "\n",
    "for url in fight_details_links:\n",
    "    try:\n",
    "        time.sleep(1.5)\n",
    "        r = requests.get(url, timeout=(connect_timeout, read_timeout))\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        max_round = soup.find_all(\"i\", class_ = 'b-fight-details__text-item')\n",
    "        max_round = max_round[2].get_text().split('Rnd')[0].strip()[-1]\n",
    "        fight_details = soup.find_all('section', class_ = 'b-fight-details__section js-fight-section')\n",
    "        fight_details = fight_details[1]\n",
    "        tds = fight_details.find_all('td')\n",
    "        row1 = []\n",
    "        event = soup.find('h2').get_text(strip=True)\n",
    "        for td in tds:\n",
    "            p_tags = td.find_all('p')\n",
    "            row1.append(p_tags[0].get_text(strip=True))\n",
    "        f1 = row1[0]\n",
    "        f1_kd = row1[1]\n",
    "        f1_sigstr = row1[2]\n",
    "        f1_sigstr_pct = row1[3]\n",
    "        f1_totstr = row1[4]\n",
    "        f1_td = row1[5]\n",
    "        f1_td_pct = row1[6]\n",
    "        f1_subatt = row1[7]\n",
    "        f1_rev = row1[8]\n",
    "        f1_ctrl = row1[9]\n",
    "        row2 = []\n",
    "        for td in tds:\n",
    "            p_tags = td.find_all('p')\n",
    "            row2.append(p_tags[1].get_text(strip=True))\n",
    "        f2 = row2[0]\n",
    "        f2_kd = row2[1]\n",
    "        f2_sigstr = row2[2]\n",
    "        f2_sigstr_pct = row2[3]\n",
    "        f2_totstr = row2[4]\n",
    "        f2_td = row2[5]\n",
    "        f2_td_pct = row2[6]\n",
    "        f2_subatt = row2[7]\n",
    "        f2_rev = row2[8]\n",
    "        f2_ctrl = row2[9]\n",
    "        stats_url = url\n",
    "\n",
    "        all_data.append({\n",
    "            'fighter1' : f1,\n",
    "            'fighter2': f2,\n",
    "            'f1_kd' : f1_kd,\n",
    "            'f1_sigstr' : f1_sigstr,\n",
    "            'f1_sigstr_pct' : f1_sigstr_pct,\n",
    "            'f1_totstr' : f1_totstr,\n",
    "            'f1_td' : f1_td,\n",
    "            'f1_td_pct' : f1_td_pct,\n",
    "            'f1_subatt' : f1_subatt,\n",
    "            'f1_rev' : f1_rev,\n",
    "            'f1_ctrl' : f1_ctrl,\n",
    "            'f2_kd' : f2_kd,\n",
    "            'f2_sigstr' : f2_sigstr,\n",
    "            'f2_sigstr_pct' : f2_sigstr_pct,\n",
    "            'f2_totstr' : f2_totstr,\n",
    "            'f2_td' : f2_td,\n",
    "            'f2_td_pct' : f2_td_pct,\n",
    "            'f2_subatt' : f2_subatt,\n",
    "            'f2_rev' : f2_rev,\n",
    "            'f2_ctrl' : f2_ctrl,\n",
    "            'event' : event,\n",
    "            'tot_round' : max_round,\n",
    "            'stats_url' : stats_url\n",
    "            })\n",
    "        success_count += 1\n",
    "        print(f\"Succcess count: {success_count}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        failure_count += 1\n",
    "        print(f\"Failure: {failure_count}\")\n",
    "        failed_requests.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955e32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stats_df = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543052ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df has reliable fighter1 (winner) and fighter2 (loser) designations, treating nulls from the join as incorrect designations \n",
    "complete_df = new_df.merge(new_stats_df, on = ['stats_url', 'fighter1', 'fighter2', 'event'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4482fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows that have improper f1 and f2 designations:  27\n"
     ]
    }
   ],
   "source": [
    "mismatched_winner_df = complete_df[complete_df['f2_sigstr'].isna()]\n",
    "right_match = complete_df[~complete_df['f2_sigstr'].isna()]\n",
    "print(\"# of rows that have improper f1 and f2 designations: \", len(mismatched_winner_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a660974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_search = mismatched_winner_df['stats_url'].tolist()\n",
    "corrected_df = new_stats_df[new_stats_df['stats_url'].isin(url_search)]\n",
    "\n",
    "# Checking work - should equal True\n",
    "len(corrected_df) == len(mismatched_winner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c3ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_df = corrected_df.rename(columns={\n",
    "'fighter1' : 'fighter2',\n",
    "'fighter2': 'fighter1',\n",
    "'f1_kd' : 'f2_kd',\n",
    "'f1_sigstr' : 'f2_sigstr',\n",
    "'f1_sigstr_pct' : 'f2_sigstr_pct',\n",
    "'f1_totstr' : 'f2_totstr',\n",
    "'f1_td' : 'f2_td',\n",
    "'f1_td_pct' : 'f2_td_pct',\n",
    "'f1_subatt' : 'f2_subatt',\n",
    "'f1_rev' : 'f2_rev',\n",
    "'f1_ctrl' : 'f2_ctrl',\n",
    "'f2_kd' : 'f1_kd',\n",
    "'f2_sigstr' : 'f1_sigstr',\n",
    "'f2_sigstr_pct' : 'f1_sigstr_pct',\n",
    "'f2_totstr' : 'f1_totstr',\n",
    "'f2_td' : 'f1_td',\n",
    "'f2_td_pct' : 'f1_td_pct',\n",
    "'f2_subatt' : 'f1_subatt',\n",
    "'f2_rev' : 'f1_rev',\n",
    "'f2_ctrl' : 'f1_ctrl'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0a2f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df = pd.concat([corrected_df, right_match], ignore_index=True)\n",
    "len(complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a5e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[['f1_sigstr_landed', 'f1_sigstr_attempt']] = complete_df['f1_sigstr'].str.split(' of ', expand=True).astype(int)\n",
    "complete_df[['f2_sigstr_landed', 'f2_sigstr_attempt']] = complete_df['f2_sigstr'].str.split(' of ', expand=True).astype(int)\n",
    "\n",
    "complete_df[['f1_totstr_landed', 'f1_totstr_attempt']] = complete_df['f1_totstr'].str.split(' of ', expand=True).astype(int)\n",
    "complete_df[['f2_totstr_landed', 'f2_totstr_attempt']] = complete_df['f2_totstr'].str.split(' of ', expand=True).astype(int)\n",
    "\n",
    "complete_df[['f1_td_landed', 'f1_td_attempt']] = complete_df['f1_td'].str.split(' of ', expand=True).astype(int)\n",
    "complete_df[['f2_td_landed', 'f2_td_attempt']] = complete_df['f2_td'].str.split(' of ', expand=True).astype(int)\n",
    "\n",
    "\n",
    "complete_df = complete_df.drop(columns=[\n",
    "'f1_sigstr', 'f2_sigstr', 'f1_totstr', 'f2_totstr', 'f1_td', 'f2_td'\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "complete_df['f1_sigstr_pct'] = complete_df.apply(lambda row: row['f1_sigstr_landed']/row['f1_sigstr_attempt'] * 100 if row['f1_sigstr_attempt'] != 0 else 0, axis=1)\n",
    "complete_df['f2_sigstr_pct'] = complete_df.apply(lambda row: row['f2_sigstr_landed']/row['f2_sigstr_attempt'] * 100 if row['f2_sigstr_attempt'] != 0 else 0, axis=1)\n",
    "\n",
    "complete_df['f2_totstr_pct'] = complete_df.apply(lambda row: row['f2_totstr_landed']/row['f2_totstr_attempt'] * 100 if row['f2_totstr_attempt'] != 0 else 0, axis=1)\n",
    "complete_df['f1_totstr_pct'] = complete_df.apply(lambda row: row['f1_totstr_landed']/row['f1_totstr_attempt'] * 100 if row['f1_totstr_attempt'] != 0 else 0, axis=1)\n",
    "\n",
    "complete_df['f1_td_pct'] = complete_df.apply(lambda row: row['f1_td_landed']/row['f1_td_attempt'] * 100 if row['f1_td_attempt'] != 0 else 0, axis=1)\n",
    "complete_df['f2_td_pct'] = complete_df.apply(lambda row: row['f2_td_landed']/row['f2_td_attempt'] * 100 if row['f2_td_attempt'] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5e26f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MM:SS time format into just seconds to help aggregate / total time in the fight\n",
    "def standard_time_format(mmss):\n",
    "    if mmss == '--':\n",
    "        return 0\n",
    "    else: minutes, seconds = map(int, mmss.split(\":\"))\n",
    "    return (minutes*60) + seconds\n",
    "\n",
    "def total_fight_time(row):\n",
    "    remainder = standard_time_format(row['times'])\n",
    "    x = row['rounds'] - 1\n",
    "    return (x*5*60) + remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a21c0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df = complete_df[~complete_df['rounds'].isna()]\n",
    "complete_df['rounds'] = complete_df['rounds'].astype(int)\n",
    "complete_df['rounds'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2f55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['f1_ctrl_sec'] = complete_df['f1_ctrl'].apply(standard_time_format)\n",
    "complete_df['f2_ctrl_sec'] = complete_df['f2_ctrl'].apply(standard_time_format)\n",
    "\n",
    "\n",
    "complete_df['tot_fight_secs'] = complete_df.apply(total_fight_time, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8c62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['more_totstr_landed'] = complete_df.apply(lambda row: 'fighter1' if row['f1_totstr_landed'] > row['f2_totstr_landed'] else ('fighter2' if row['f1_totstr_landed'] < row['f2_totstr_landed'] else \"equal\"), axis=1)\n",
    "complete_df['more_totstr_attempt'] = complete_df.apply(lambda row: 'fighter1' if row['f1_totstr_attempt'] > row['f2_totstr_attempt'] else ('fighter2' if row['f1_totstr_attempt'] < row['f2_totstr_attempt'] else \"equal\"), axis=1)\n",
    "\n",
    "complete_df['more_sigstr_attempt'] = complete_df.apply(lambda row: 'fighter1' if row['f1_sigstr_attempt'] > row['f2_sigstr_attempt'] else ('fighter2' if row['f1_sigstr_attempt'] < row['f2_sigstr_attempt'] else \"equal\"),axis=1)\n",
    "complete_df['more_sigstr_landed'] = complete_df.apply(lambda row: 'fighter1' if row['f1_sigstr_landed'] > row['f2_sigstr_landed'] else ('fighter2' if row['f1_sigstr_landed'] < row['f2_sigstr_landed'] else \"equal\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "965f4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_methods(x):\n",
    "    if \"SUB\" in x:\n",
    "        return \"SUB\"\n",
    "    elif \"KO\" in x:\n",
    "        return \"KO/TKO\"\n",
    "    elif \"DEC\" in x:\n",
    "        return \"DEC\"\n",
    "    else: \n",
    "        return \"DQ/CNC/Overturned/Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f9bd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total_stats = pd.read_csv(\"Complete Stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09571dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to Complete Stats Table\n",
    "new_total_stats = pd.concat([current_df, complete_df], ignore_index=True)\n",
    "\n",
    "new_total_stats['method'] = new_total_stats['method'].apply(consolidate_methods)\n",
    "\n",
    "new_total_stats.drop_duplicates(inplace=True)\n",
    "\n",
    "new_total_stats.to_csv(\"Complete Stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ea708ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_df['rounds'] = current_df['rounds'].astype(int)\n",
    "# current_df['tot_fight_secs'] = current_df.apply(total_fight_time, axis=1)\n",
    "# current_df.to_csv(\"Complete Stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7ee601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_total_stats['dates'] = pd.to_datetime(new_total_stats['dates'])\n",
    "\n",
    "\n",
    "#new_total_stats.sort_values(by='dates', ascending=False).head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f754089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv(\"Complete Stats.csv\")\n",
    "\n",
    "# separate into two tables then append each other to normalize the data\n",
    "# stats_df.columns\n",
    "f1_df = stats_df[['event', 'fighter1', 'weight', 'rounds',\n",
    "       'times', 'method', 'locations', 'dates', 'stats_url', 'f1_kd',\n",
    "       'f1_sigstr_pct', 'f1_td_pct', 'f1_subatt', 'f1_rev', 'f1_ctrl',\n",
    "       'f1_sigstr_landed', 'f1_sigstr_attempt', 'f1_totstr_landed', 'f1_totstr_attempt', 'f1_td_landed',\n",
    "       'f1_td_attempt',\n",
    "       'f1_totstr_pct', 'f1_ctrl_sec', 'more_totstr_landed',\n",
    "       'more_totstr_attempt', 'more_sigstr_attempt', 'more_sigstr_landed', 'tot_fight_secs', 'tot_round']].copy()\n",
    "\n",
    "f1_df[\"is_winner\"] = True\n",
    "f1_df[\"fighter_num\"] = \"fighter1\"\n",
    "f1_df.rename(columns={\"fighter1\" : \"fighter\" , 'f1_kd' : 'kd',\n",
    "       'f1_sigstr_pct' : 'sigstr_pct', 'f1_td_pct' : 'td_pct', 'f1_subatt' : 'subatt', 'f1_rev' : 'rev', 'f1_ctrl' : 'ctrl', 'f1_sigstr_landed' : 'sigstr_landed',\n",
    "       'f1_sigstr_attempt' : 'sigstr_attempt',\n",
    "       'f1_totstr_landed' : 'totstr_landed', 'f1_totstr_attempt' : 'totstr_attempt', 'f1_td_landed' : 'td_landed', 'f1_td_attempt' : 'td_attempt', 'f1_totstr_pct' : 'totstr_pct', 'f1_ctrl_sec' : 'ctrl_sec'}, inplace=True)\n",
    "\n",
    "f2_df = stats_df[['event', 'fighter2', 'weight', 'rounds',\n",
    "       'times', 'method', 'locations', 'dates', 'stats_url', 'f2_kd',\n",
    "       'f2_sigstr_pct', 'f2_td_pct', 'f2_subatt', 'f2_rev', 'f2_ctrl', 'f2_sigstr_landed',\n",
    "       'f2_sigstr_attempt',\n",
    "       'f2_totstr_landed', 'f2_totstr_attempt', 'f2_td_landed', 'f2_td_attempt', 'f2_totstr_pct', 'f2_ctrl_sec', 'more_totstr_landed',\n",
    "       'more_totstr_attempt', 'more_sigstr_attempt', 'more_sigstr_landed','tot_fight_secs','tot_round']].copy()\n",
    "\n",
    "f2_df[\"is_winner\"] = False\n",
    "f2_df[\"fighter_num\"] = \"fighter2\"\n",
    "f2_df.rename(columns={\"fighter2\" : \"fighter\", \"f2_kd\": \"kd\",\n",
    "       'f2_sigstr_pct': 'sigstr_pct', 'f2_td_pct': 'td_pct', 'f2_subatt' : 'subatt', 'f2_rev': 'rev', 'f2_ctrl': 'ctrl', 'f2_sigstr_landed': 'sigstr_landed',\n",
    "       'f2_sigstr_attempt' : 'sigstr_attempt',\n",
    "       'f2_totstr_landed' : 'totstr_landed', 'f2_totstr_attempt' : 'totstr_attempt', 'f2_td_landed' : 'td_landed', 'f2_td_attempt' : 'td_attempt', 'f2_totstr_pct' : 'totstr_pct', 'f2_ctrl_sec' : 'ctrl_sec'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe93224",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = pd.concat([f1_df, f2_df], ignore_index = True)\n",
    "norm_df['method'] = norm_df['method'].apply(consolidate_methods)\n",
    "norm_df.to_csv(\"Normalized Stats Table.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
